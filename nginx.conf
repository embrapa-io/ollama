worker_processes auto;

events {
  worker_connections 1024;
  multi_accept on;
}

http {
  # Upstream with keepalive for connection reuse
  upstream ollama_backend {
    server ollama:11434;
    keepalive 32;
  }

  server {
    listen 11434;

    # Security: block management endpoints
    location ~ ^/api/(pull|create|push|delete|copy) {
      return 403;
    }

    # Health check endpoint
    location /health {
      proxy_pass http://ollama_backend/;
      proxy_connect_timeout 5s;
      proxy_read_timeout 5s;
    }

    # Main API endpoints
    location / {
      # Large contexts (16K tokens can be ~100KB+ per request)
      client_max_body_size 100M;

      # Timeouts for large model inference (70B can be slow)
      proxy_connect_timeout 60s;
      proxy_send_timeout 600s;
      proxy_read_timeout 600s;

      # Buffering for non-streaming responses
      proxy_buffer_size 512k;
      proxy_buffers 16 512k;
      proxy_busy_buffers_size 1m;

      # HTTP/1.1 with keepalive
      proxy_http_version 1.1;
      proxy_set_header Connection "";

      # Headers
      proxy_set_header Host $host;
      proxy_set_header X-Real-IP $remote_addr;
      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

      proxy_pass http://ollama_backend;
    }

    # Streaming endpoints (chat, generate) - disable buffering for SSE
    location ~ ^/api/(chat|generate) {
      client_max_body_size 100M;

      # Extended timeouts for streaming
      proxy_connect_timeout 60s;
      proxy_send_timeout 600s;
      proxy_read_timeout 600s;

      # Disable buffering for Server-Sent Events
      proxy_buffering off;
      proxy_cache off;

      # HTTP/1.1 required for chunked transfer
      proxy_http_version 1.1;
      proxy_set_header Connection "";

      # Headers
      proxy_set_header Host $host;
      proxy_set_header X-Real-IP $remote_addr;
      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

      proxy_pass http://ollama_backend;
    }

    # Embeddings endpoint - optimized for batch processing
    location /api/embed {
      client_max_body_size 100M;

      # Embeddings are usually faster
      proxy_connect_timeout 30s;
      proxy_send_timeout 300s;
      proxy_read_timeout 300s;

      # Larger buffers for batch embeddings
      proxy_buffer_size 1m;
      proxy_buffers 16 1m;
      proxy_busy_buffers_size 2m;

      proxy_http_version 1.1;
      proxy_set_header Connection "";
      proxy_set_header Host $host;
      proxy_set_header X-Real-IP $remote_addr;
      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

      proxy_pass http://ollama_backend;
    }
  }
}
